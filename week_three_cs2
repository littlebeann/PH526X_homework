import os
import pandas as pd
import numpy as np
from collections import Counter

def count_words_fast(text):
    text = text.lower()
    skips = [".", ",", ";", ":", "'", '"', "\n", "!", "?", "(", ")"]
    for ch in skips:
        text = text.replace(ch, "")
    word_counts = Counter(text.split(" "))
    return word_counts

def word_stats(word_counts):
    num_unique = len(word_counts)
    counts = word_counts.values()
    return (num_unique, counts)

#exercise 1
hamlets = pd.read_csv("asset-v1-HarvardX+PH526x+2T2019+type@asset+block@hamlets.csv", index_col = 0)
print(len(hamlets["language"]))

#exercise 2
language, text = hamlets.iloc[0]
counted_text = count_words_fast(text)
data = pd.DataFrame({"word": list(counted_text.keys()), "count": list(counted_text.values())})
index = list(data['word']).index('hamlet')
print(data['count'][index])

#exercise 3
length_column_data = []
for word in list(data["word"]):
    length = len(word)
    length_column_data.append(length)
data["length"] = length_column_data

word_frequency = []
for count in list(data["count"]):
    if count > 10:
        frequency = "frequent"
    if 1 < count <= 10:
        frequency = "infrequent"
    if count == 1:
        frequency = "unique"
    word_frequency.append(frequency)
data ["frequency"] = word_frequency
print(list(data["frequency"]).count("unique"))

#exercise 4
language, text = hamlets.iloc[0]
sub_data = pd.DataFrame()
frequency = ["frequent", "infrequent", "unique"]
sub_data["language"] = [language,language,language]
sub_data["frequency"] = frequency

mean_word_length = []
for f in frequency:
    df = data.loc[data["frequency"]==f,"length"] #like vlookup, but all matching the criteria
    mean_word_length.append(df.mean())
sub_data["mean_word_length"] = mean_word_length

num_words = []
for k in frequency:
    df1 = data.loc[data["frequency"] == k, "count"]
    num_words.append(df1.sum())
sub_data["num_words"] = num_words

#exercise 5
language, text = hamlets.iloc[2]
def summarize_text(language, text):
    counted_text = count_words_fast(text)

    data = pd.DataFrame({
        "word": list(counted_text.keys()),
        "count": list(counted_text.values())
    })
    
    data.loc[data["count"] > 10,  "frequency"] = "frequent"
    data.loc[data["count"] <= 10, "frequency"] = "infrequent"
    data.loc[data["count"] == 1,  "frequency"] = "unique"
    
    data["length"] = data["word"].apply(len)
    
    sub_data = pd.DataFrame({
        "language": language,
        "frequency": ["frequent","infrequent","unique"],
        "mean_word_length": data.groupby(by = "frequency")["length"].mean(),
        "num_words": data.groupby(by = "frequency").size()
    })
    
    return(sub_data)

grouped_data = pd.DataFrame(columns = ["language", "frequency", "mean_word_length", "num_words"])

for i in range (hamlets.shape[0]): 
    language, text = hamlets.iloc[i]
    sub_data = summarize_text(language, text)
    grouped_data = grouped_data.append(sub_data)
print(grouped_data)

#exercise 6
colors = {"Portuguese": "green", "English": "blue", "German": "red"}
markers = {"frequent": "o","infrequent": "s", "unique": "^"}
import matplotlib.pyplot as plt
for i in range(grouped_data.shape[0]):
    row = grouped_data.iloc[i]
    plt.plot(row.mean_word_length, row.num_words,
        marker=markers[row.frequency],
        color = colors[row.language],
        markersize = 10
    )

color_legend = []
marker_legend = []
for color in colors:
    color_legend.append(
        plt.plot([], [],
        color=colors[color],
        marker="o",
        label = color, markersize = 10, linestyle="None")
    )
for marker in markers:
    marker_legend.append(
        plt.plot([], [],
        color="k",
        marker=markers[marker],
        label = marker, markersize = 10, linestyle="None")
    )
plt.legend(numpoints=1, loc = "upper left")

plt.xlabel("Mean Word Length")
plt.ylabel("Number of Words")
plt.savefig("casestudytwo.pdf")

